pub struct QueryStat {
    pub database_id: i64,
    pub calls: i64,
    pub total_time: f64,
}
/// Generated by pco_store to store and load compressed versions of [QueryStat]
pub struct CompressedQueryStats {
    pub database_id: i64,
    calls: Vec<u8>,
    total_time: Vec<u8>,
}
impl CompressedQueryStats {
    /// Loads data for the specified filters.
    ///
    /// For models with a timestamp, [decompress][Self::decompress] automatically filters out
    /// rows outside the requested time range.
    pub async fn load(
        db: &deadpool_postgres::Object,
        database_id: &[i64],
    ) -> anyhow::Result<Vec<CompressedQueryStats>> {
        if database_id.is_empty() {
            return ::anyhow::__private::Err({
                use ::anyhow::__private::kind::*;
                let error = match "database_id".to_string() + "must be specified" {
                    error => (&error).anyhow_kind().new(error),
                };
                error
            });
        }
        let sql = "SELECT * FROM query_stats WHERE database_id = ANY($1)";
        let mut results = Vec::new();
        for row in db.query(&db.prepare_cached(&sql).await?, &[&database_id]).await? {
            results
                .push(CompressedQueryStats {
                    database_id: row.get(0usize),
                    calls: row.get(1usize),
                    total_time: row.get(2usize),
                });
        }
        Ok(results)
    }
    /// Deletes data for the specified filters, returning it to the caller.
    ///
    /// For models with a timestamp, [decompress][Self::decompress] **will not** filter out
    /// rows outside the requested time range.
    pub async fn delete(
        db: &deadpool_postgres::Object,
        database_id: &[i64],
    ) -> anyhow::Result<Vec<CompressedQueryStats>> {
        if database_id.is_empty() {
            return ::anyhow::__private::Err({
                use ::anyhow::__private::kind::*;
                let error = match "database_id".to_string() + "must be specified" {
                    error => (&error).anyhow_kind().new(error),
                };
                error
            });
        }
        let sql = "DELETE FROM query_stats WHERE database_id = ANY($1) RETURNING *";
        let mut results = Vec::new();
        for row in db.query(&db.prepare_cached(&sql).await?, &[&database_id]).await? {
            results
                .push(CompressedQueryStats {
                    database_id: row.get(0usize),
                    calls: row.get(1usize),
                    total_time: row.get(2usize),
                });
        }
        Ok(results)
    }
    /// Decompresses a group of data points.
    pub fn decompress(self) -> anyhow::Result<Vec<QueryStat>> {
        let mut results = Vec::new();
        let calls: Vec<i64> = if self.calls.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.calls)?
        };
        let total_time: Vec<i64> = if self.total_time.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.total_time)?
        };
        let len = [calls.len(), total_time.len()].into_iter().max().unwrap_or(0);
        for index in 0..len {
            let row = QueryStat {
                database_id: self.database_id,
                calls: calls.get(index).cloned().unwrap_or_default(),
                total_time: total_time.get(index).cloned().unwrap_or_default() as f64
                    / 100f32 as f64,
            };
            if true {
                results.push(row);
            }
        }
        Ok(results)
    }
    /// Writes the provided data to disk.
    pub async fn store(
        db: &deadpool_postgres::Object,
        rows: Vec<QueryStat>,
    ) -> anyhow::Result<()> {
        if rows.is_empty() {
            return Ok(());
        }
        let mut grouped_rows: std::collections::HashMap<_, Vec<QueryStat>> = std::collections::HashMap::new();
        for row in rows {
            grouped_rows.entry((row.database_id,)).or_default().push(row);
        }
        let sql = "COPY query_stats (database_id, calls, total_time) FROM STDIN BINARY";
        let types = &[
            tokio_postgres::types::Type::INT8,
            tokio_postgres::types::Type::BYTEA,
            tokio_postgres::types::Type::BYTEA,
        ];
        let stmt = db.copy_in(&db.prepare_cached(&sql).await?).await?;
        let writer = tokio_postgres::binary_copy::BinaryCopyInWriter::new(stmt, types);
        let mut writer = writer;
        #[allow(unused_mut)]
        let mut writer = unsafe {
            ::pin_utils::core_reexport::pin::Pin::new_unchecked(&mut writer)
        };
        for rows in grouped_rows.into_values() {
            writer
                .as_mut()
                .write(
                    &[
                        &rows[0].database_id,
                        &::pco::standalone::simpler_compress(
                                &rows.iter().map(|r| r.calls).collect::<Vec<_>>(),
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                        &::pco::standalone::simpler_compress(
                                &rows
                                    .iter()
                                    .map(|r| (r.total_time * 100f32 as f64).round() as i64)
                                    .collect::<Vec<_>>(),
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                    ],
                )
                .await?;
        }
        writer.finish().await?;
        Ok(())
    }
}
