pub struct QueryStat {
    pub database_id: i64,
    pub collected_at: SystemTime,
    pub collected_secs: i64,
    pub fingerprint: i64,
    pub postgres_role_id: i64,
    pub calls: i64,
    pub rows: i64,
    pub total_time: f64,
    pub io_time: f64,
    pub shared_blks_hit: i64,
    pub shared_blks_read: i64,
}
/// Generated by pco_store to store and load compressed versions of [QueryStat]
pub struct CompressedQueryStats {
    pub database_id: i64,
    pub filter: bool,
    pub filter_start: SystemTime,
    pub filter_end: SystemTime,
    pub start_at: SystemTime,
    pub end_at: SystemTime,
    collected_at: Vec<u8>,
    collected_secs: Vec<u8>,
    fingerprint: Vec<u8>,
    postgres_role_id: Vec<u8>,
    calls: Vec<u8>,
    rows: Vec<u8>,
    total_time: Vec<u8>,
    io_time: Vec<u8>,
    shared_blks_hit: Vec<u8>,
    shared_blks_read: Vec<u8>,
}
impl CompressedQueryStats {
    /// Loads data for the specified filters.
    ///
    /// For models with a timestamp, [decompress][Self::decompress] automatically filters out
    /// rows outside the requested time range.
    pub async fn load(
        db: &deadpool_postgres::Object,
        database_id: &[i64],
        filter_start: SystemTime,
        filter_end: SystemTime,
    ) -> anyhow::Result<Vec<CompressedQueryStats>> {
        if database_id.is_empty() {
            return Err(
                anyhow::Error::msg("database_id".to_string() + "must be specified"),
            );
        }
        let sql = "SELECT * FROM query_stats WHERE database_id = ANY($1) AND end_at >= $2 AND start_at <= $3";
        let mut results = Vec::new();
        for row in db
            .query(
                &db.prepare_cached(&sql).await?,
                &[&database_id, &filter_start, &filter_end],
            )
            .await?
        {
            results
                .push(CompressedQueryStats {
                    database_id: row.get(0usize),
                    start_at: row.get(1usize),
                    end_at: row.get(2usize),
                    collected_at: row.get(3usize),
                    collected_secs: row.get(4usize),
                    fingerprint: row.get(5usize),
                    postgres_role_id: row.get(6usize),
                    calls: row.get(7usize),
                    rows: row.get(8usize),
                    total_time: row.get(9usize),
                    io_time: row.get(10usize),
                    shared_blks_hit: row.get(11usize),
                    shared_blks_read: row.get(12usize),
                    filter: true,
                    filter_start,
                    filter_end,
                });
        }
        Ok(results)
    }
    /// Deletes data for the specified filters, returning it to the caller.
    ///
    /// For models with a timestamp, [decompress][Self::decompress] **will not** filter out
    /// rows outside the requested time range.
    pub async fn delete(
        db: &deadpool_postgres::Object,
        database_id: &[i64],
        filter_start: SystemTime,
        filter_end: SystemTime,
    ) -> anyhow::Result<Vec<CompressedQueryStats>> {
        if database_id.is_empty() {
            return Err(
                anyhow::Error::msg("database_id".to_string() + "must be specified"),
            );
        }
        let sql = "DELETE FROM query_stats WHERE database_id = ANY($1) AND end_at >= $2 AND start_at <= $3 RETURNING *";
        let mut results = Vec::new();
        for row in db
            .query(
                &db.prepare_cached(&sql).await?,
                &[&database_id, &filter_start, &filter_end],
            )
            .await?
        {
            results
                .push(CompressedQueryStats {
                    database_id: row.get(0usize),
                    start_at: row.get(1usize),
                    end_at: row.get(2usize),
                    collected_at: row.get(3usize),
                    collected_secs: row.get(4usize),
                    fingerprint: row.get(5usize),
                    postgres_role_id: row.get(6usize),
                    calls: row.get(7usize),
                    rows: row.get(8usize),
                    total_time: row.get(9usize),
                    io_time: row.get(10usize),
                    shared_blks_hit: row.get(11usize),
                    shared_blks_read: row.get(12usize),
                    filter: false,
                    filter_start,
                    filter_end,
                });
        }
        Ok(results)
    }
    /// Decompresses a group of data points.
    pub fn decompress(self) -> anyhow::Result<Vec<QueryStat>> {
        let mut results = Vec::new();
        let collected_at: Vec<u64> = if self.collected_at.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.collected_at)?
        };
        let collected_secs: Vec<i64> = if self.collected_secs.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.collected_secs)?
        };
        let fingerprint: Vec<i64> = if self.fingerprint.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.fingerprint)?
        };
        let postgres_role_id: Vec<i64> = if self.postgres_role_id.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.postgres_role_id)?
        };
        let calls: Vec<i64> = if self.calls.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.calls)?
        };
        let rows: Vec<i64> = if self.rows.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.rows)?
        };
        let total_time: Vec<f64> = if self.total_time.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.total_time)?
        };
        let io_time: Vec<f64> = if self.io_time.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.io_time)?
        };
        let shared_blks_hit: Vec<i64> = if self.shared_blks_hit.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.shared_blks_hit)?
        };
        let shared_blks_read: Vec<i64> = if self.shared_blks_read.is_empty() {
            Vec::new()
        } else {
            ::pco::standalone::simple_decompress(&self.shared_blks_read)?
        };
        let len = [
            collected_at.len(),
            collected_secs.len(),
            fingerprint.len(),
            postgres_role_id.len(),
            calls.len(),
            rows.len(),
            total_time.len(),
            io_time.len(),
            shared_blks_hit.len(),
            shared_blks_read.len(),
        ]
            .into_iter()
            .max()
            .unwrap_or(0);
        for index in 0..len {
            let row = QueryStat {
                database_id: self.database_id,
                collected_at: SystemTime::UNIX_EPOCH
                    + std::time::Duration::from_micros(collected_at[index]),
                collected_secs: collected_secs.get(index).cloned().unwrap_or_default(),
                fingerprint: fingerprint.get(index).cloned().unwrap_or_default(),
                postgres_role_id: postgres_role_id
                    .get(index)
                    .cloned()
                    .unwrap_or_default(),
                calls: calls.get(index).cloned().unwrap_or_default(),
                rows: rows.get(index).cloned().unwrap_or_default(),
                total_time: total_time.get(index).cloned().unwrap_or_default(),
                io_time: io_time.get(index).cloned().unwrap_or_default(),
                shared_blks_hit: shared_blks_hit.get(index).cloned().unwrap_or_default(),
                shared_blks_read: shared_blks_read
                    .get(index)
                    .cloned()
                    .unwrap_or_default(),
            };
            if !self.filter
                || row.collected_at >= self.filter_start
                    && row.collected_at <= self.filter_end
            {
                results.push(row);
            }
        }
        Ok(results)
    }
    /// Writes the provided data to disk.
    pub async fn store(
        db: &deadpool_postgres::Object,
        rows: Vec<QueryStat>,
    ) -> anyhow::Result<()> {
        if rows.is_empty() {
            return Ok(());
        }
        let mut grouped_rows: std::collections::HashMap<_, Vec<QueryStat>> = std::collections::HashMap::new();
        for row in rows {
            grouped_rows.entry((row.database_id,)).or_default().push(row);
        }
        let sql = "COPY query_stats (database_id, start_at, end_at, collected_at, collected_secs, fingerprint, postgres_role_id, calls, rows, total_time, io_time, shared_blks_hit, shared_blks_read) FROM STDIN BINARY";
        let types = &[
            tokio_postgres::types::Type::INT8,
            tokio_postgres::types::Type::TIMESTAMPTZ,
            tokio_postgres::types::Type::TIMESTAMPTZ,
            tokio_postgres::types::Type::BYTEA,
            tokio_postgres::types::Type::BYTEA,
            tokio_postgres::types::Type::BYTEA,
            tokio_postgres::types::Type::BYTEA,
            tokio_postgres::types::Type::BYTEA,
            tokio_postgres::types::Type::BYTEA,
            tokio_postgres::types::Type::BYTEA,
            tokio_postgres::types::Type::BYTEA,
            tokio_postgres::types::Type::BYTEA,
            tokio_postgres::types::Type::BYTEA,
        ];
        let stmt = db.copy_in(&db.prepare_cached(&sql).await?).await?;
        let writer = tokio_postgres::binary_copy::BinaryCopyInWriter::new(stmt, types);
        let mut writer = writer;
        #[allow(unused_mut)]
        let mut writer = unsafe {
            ::pin_utils::core_reexport::pin::Pin::new_unchecked(&mut writer)
        };
        for rows in grouped_rows.into_values() {
            let collected_at: Vec<_> = rows.iter().map(|s| s.collected_at).collect();
            let start_at = *collected_at.iter().min().unwrap();
            let end_at = *collected_at.iter().max().unwrap();
            let collected_at: Vec<u64> = collected_at
                .into_iter()
                .map(|t| {
                    t.duration_since(SystemTime::UNIX_EPOCH).unwrap().as_micros() as u64
                })
                .collect();
            writer
                .as_mut()
                .write(
                    &[
                        &rows[0].database_id,
                        &start_at,
                        &end_at,
                        &::pco::standalone::simpler_compress(
                                &collected_at,
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                        &::pco::standalone::simpler_compress(
                                &rows.iter().map(|r| r.collected_secs).collect::<Vec<_>>(),
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                        &::pco::standalone::simpler_compress(
                                &rows.iter().map(|r| r.fingerprint).collect::<Vec<_>>(),
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                        &::pco::standalone::simpler_compress(
                                &rows
                                    .iter()
                                    .map(|r| r.postgres_role_id)
                                    .collect::<Vec<_>>(),
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                        &::pco::standalone::simpler_compress(
                                &rows.iter().map(|r| r.calls).collect::<Vec<_>>(),
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                        &::pco::standalone::simpler_compress(
                                &rows.iter().map(|r| r.rows).collect::<Vec<_>>(),
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                        &::pco::standalone::simpler_compress(
                                &rows.iter().map(|r| r.total_time).collect::<Vec<_>>(),
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                        &::pco::standalone::simpler_compress(
                                &rows.iter().map(|r| r.io_time).collect::<Vec<_>>(),
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                        &::pco::standalone::simpler_compress(
                                &rows.iter().map(|r| r.shared_blks_hit).collect::<Vec<_>>(),
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                        &::pco::standalone::simpler_compress(
                                &rows
                                    .iter()
                                    .map(|r| r.shared_blks_read)
                                    .collect::<Vec<_>>(),
                                ::pco::DEFAULT_COMPRESSION_LEVEL,
                            )
                            .unwrap(),
                    ],
                )
                .await?;
        }
        writer.finish().await?;
        Ok(())
    }
}
